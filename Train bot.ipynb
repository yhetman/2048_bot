{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math, copy\n",
    "import numpy as np\n",
    "\n",
    "from classNeuron import Neuron\n",
    "from classNetwork import Network\n",
    "import numpy as np\n",
    "from classGame2048 import Game2048\n",
    "import math\n",
    "import tkinter as tk\n",
    "import time\n",
    "import pickle\n",
    "import concurrent.futures\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0.]\n",
      " [4. 0. 4. 0.]\n",
      " [0. 0. 0. 2.]\n",
      " [0. 2. 0. 0.]]\n",
      "====================\n",
      "[[0. 0. 0. 0.]\n",
      " [0. 0. 0. 8.]\n",
      " [0. 0. 2. 2.]\n",
      " [0. 0. 0. 2.]]\n",
      "--------------------\n",
      "[0. 0. 0. 0. 0. 0. 0. 8. 0. 0. 2. 2. 0. 0. 0. 2.]\n",
      "--------------------\n",
      "94.0\n"
     ]
    }
   ],
   "source": [
    "mygame = Game2048(4)\n",
    "mygame.generate_tile()\n",
    "mygame.generate_tile()\n",
    "mygame.show_state()\n",
    "print('====================')\n",
    "mygame.swipe('right')\n",
    "mygame.show_state()\n",
    "print('--------------------')\n",
    "print(mygame.get_state(True))\n",
    "print('--------------------')\n",
    "print(mygame.get_score())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Neuron class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.0\n"
     ]
    }
   ],
   "source": [
    "n = Neuron(np.array([-100, -100]), -100000)\n",
    "print(n.forward(np.array([25600000, 25600000])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.99980999 -1.        ]\n"
     ]
    }
   ],
   "source": [
    "X1 = np.array([[1], [4], [2], [-4]])\n",
    "X2 = np.array([[1, 2, 3,-3], [5,-20,12,0.26]])\n",
    "b1 = np.array([1,1,1,1])\n",
    "b2 = np.array([1,1])\n",
    "N = Network([X1,X2],[b1,b2])\n",
    "I = np.array([1,0.3,-1,3])\n",
    "print(N.evaluate(I))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing to run 10 generations...\n",
      "Starting batch 0\n",
      "Generation 0 - maximum: 436.0  median: 96.0 minimum: 24.0\n",
      "Model 0 Saved\n",
      "Starting batch 1\n",
      "Generation 0 - maximum: 768.0  median: 92.0 minimum: 24.0\n",
      "Model 1 Saved\n",
      "Starting batch 2\n",
      "Generation 0 - maximum: 748.0  median: 96.0 minimum: 24.0\n",
      "Model 2 Saved\n",
      "Starting batch 3\n",
      "Generation 0 - maximum: 1618.0  median: 98.0 minimum: 24.0\n",
      "Model 3 Saved\n",
      "Starting batch 4\n",
      "Generation 0 - maximum: 448.0  median: 98.0 minimum: 24.0\n",
      "Model 4 Saved\n",
      "Starting batch 5\n",
      "Generation 0 - maximum: 458.0  median: 100.0 minimum: 24.0\n",
      "Model 5 Saved\n",
      "Starting batch 6\n",
      "Generation 0 - maximum: 826.0  median: 100.0 minimum: 24.0\n",
      "Model 6 Saved\n",
      "Starting batch 7\n",
      "Generation 0 - maximum: 824.0  median: 100.0 minimum: 24.0\n",
      "Model 7 Saved\n",
      "Starting batch 8\n",
      "Generation 0 - maximum: 804.0  median: 100.0 minimum: 24.0\n",
      "Model 8 Saved\n",
      "Starting batch 9\n",
      "Generation 0 - maximum: 862.0  median: 104.0 minimum: 24.0\n",
      "Model 9 Saved\n"
     ]
    }
   ],
   "source": [
    "from classGeneticLearner import GeneticLearner\n",
    "\n",
    "fname = './models/model_'\n",
    "n_agents = 1000\n",
    "generations_per_batch = 1\n",
    "n_batches = 10\n",
    "total_generations = generations_per_batch * n_batches\n",
    "print('Preparing to run ' + str(total_generations) +' generations...')\n",
    "\n",
    "G = GeneticLearner(n_agents,[16,8,4],seed = 4)\n",
    "for i in range(n_batches):\n",
    "    print(\"Starting batch \" + str(i))\n",
    "    G.run_n_generations(generations_per_batch)\n",
    "    gen_num = i * generations_per_batch\n",
    "    save_model_state(G, fname + str(gen_num) + '.p')\n",
    "    print(\"Model \" + str(gen_num) + \" Saved\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conitnue training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading models/model_193.p and running 1000 more generations\n",
      "Starting batch 0\n",
      "Generation 0 - maximum: 1606.0  median: 444.0 minimum: 24.0\n",
      "Model 194 Saved\n",
      "Starting batch 1\n",
      "Generation 0 - maximum: 1584.0  median: 452.0 minimum: 24.0\n",
      "Model 195 Saved\n",
      "Starting batch 2\n",
      "Generation 0 - maximum: 1594.0  median: 444.0 minimum: 24.0\n",
      "Model 196 Saved\n",
      "Starting batch 3\n",
      "Generation 0 - maximum: 1634.0  median: 444.0 minimum: 24.0\n",
      "Model 197 Saved\n",
      "Starting batch 4\n",
      "Generation 0 - maximum: 1586.0  median: 444.0 minimum: 24.0\n",
      "Model 198 Saved\n",
      "Starting batch 5\n",
      "Generation 0 - maximum: 2912.0  median: 450.0 minimum: 24.0\n",
      "Model 199 Saved\n",
      "Starting batch 6\n",
      "Generation 0 - maximum: 1612.0  median: 450.0 minimum: 24.0\n",
      "Model 200 Saved\n",
      "Starting batch 7\n",
      "Generation 0 - maximum: 1608.0  median: 450.0 minimum: 24.0\n",
      "Model 201 Saved\n",
      "Starting batch 8\n",
      "Generation 0 - maximum: 2950.0  median: 451.0 minimum: 24.0\n",
      "Model 202 Saved\n",
      "Starting batch 9\n",
      "Generation 0 - maximum: 2946.0  median: 455.0 minimum: 24.0\n",
      "Model 203 Saved\n",
      "Starting batch 10\n",
      "Generation 0 - maximum: 1604.0  median: 458.0 minimum: 24.0\n",
      "Model 204 Saved\n",
      "Starting batch 11\n",
      "Generation 0 - maximum: 2950.0  median: 456.0 minimum: 24.0\n",
      "Model 205 Saved\n",
      "Starting batch 12\n",
      "Generation 0 - maximum: 1632.0  median: 453.0 minimum: 24.0\n",
      "Model 206 Saved\n",
      "Starting batch 13\n",
      "Generation 0 - maximum: 1608.0  median: 448.0 minimum: 24.0\n",
      "Model 207 Saved\n",
      "Starting batch 14\n",
      "Generation 0 - maximum: 2954.0  median: 450.0 minimum: 24.0\n",
      "Model 208 Saved\n",
      "Starting batch 15\n",
      "Generation 0 - maximum: 1632.0  median: 479.0 minimum: 24.0\n",
      "Model 209 Saved\n",
      "Starting batch 16\n",
      "Generation 0 - maximum: 2916.0  median: 460.0 minimum: 24.0\n",
      "Model 210 Saved\n",
      "Starting batch 17\n",
      "Generation 0 - maximum: 1576.0  median: 754.0 minimum: 24.0\n",
      "Model 211 Saved\n",
      "Starting batch 18\n",
      "Generation 0 - maximum: 2958.0  median: 465.0 minimum: 24.0\n",
      "Model 212 Saved\n",
      "Starting batch 19\n",
      "Generation 0 - maximum: 2956.0  median: 745.0 minimum: 24.0\n",
      "Model 213 Saved\n",
      "Starting batch 20\n",
      "Generation 0 - maximum: 2932.0  median: 756.0 minimum: 24.0\n",
      "Model 214 Saved\n",
      "Starting batch 21\n",
      "Generation 0 - maximum: 1612.0  median: 464.0 minimum: 24.0\n",
      "Model 215 Saved\n",
      "Starting batch 22\n",
      "Generation 0 - maximum: 2940.0  median: 465.0 minimum: 24.0\n",
      "Model 216 Saved\n",
      "Starting batch 23\n",
      "Generation 0 - maximum: 1624.0  median: 480.0 minimum: 24.0\n",
      "Model 217 Saved\n",
      "Starting batch 24\n",
      "Generation 0 - maximum: 1630.0  median: 756.0 minimum: 24.0\n",
      "Model 218 Saved\n",
      "Starting batch 25\n",
      "Generation 0 - maximum: 1594.0  median: 761.0 minimum: 24.0\n",
      "Model 219 Saved\n",
      "Starting batch 26\n",
      "Generation 0 - maximum: 1614.0  median: 769.0 minimum: 24.0\n",
      "Model 220 Saved\n",
      "Starting batch 27\n",
      "Generation 0 - maximum: 3002.0  median: 774.0 minimum: 24.0\n",
      "Model 221 Saved\n",
      "Starting batch 28\n",
      "Generation 0 - maximum: 2940.0  median: 758.0 minimum: 24.0\n",
      "Model 222 Saved\n",
      "Starting batch 29\n",
      "Generation 0 - maximum: 1604.0  median: 768.0 minimum: 24.0\n",
      "Model 223 Saved\n",
      "Starting batch 30\n",
      "Generation 0 - maximum: 2920.0  median: 758.0 minimum: 24.0\n",
      "Model 224 Saved\n",
      "Starting batch 31\n",
      "Generation 0 - maximum: 1596.0  median: 768.0 minimum: 24.0\n",
      "Model 225 Saved\n",
      "Starting batch 32\n",
      "Generation 0 - maximum: 1604.0  median: 770.0 minimum: 24.0\n",
      "Model 226 Saved\n",
      "Starting batch 33\n",
      "Generation 0 - maximum: 2992.0  median: 770.0 minimum: 24.0\n",
      "Model 227 Saved\n",
      "Starting batch 34\n",
      "Generation 0 - maximum: 2962.0  median: 774.0 minimum: 24.0\n",
      "Model 228 Saved\n",
      "Starting batch 35\n",
      "Generation 0 - maximum: 2954.0  median: 766.0 minimum: 24.0\n",
      "Model 229 Saved\n",
      "Starting batch 36\n",
      "Generation 0 - maximum: 2914.0  median: 776.0 minimum: 24.0\n",
      "Model 230 Saved\n",
      "Starting batch 37\n",
      "Generation 0 - maximum: 2980.0  median: 780.0 minimum: 24.0\n",
      "Model 231 Saved\n",
      "Starting batch 38\n",
      "Generation 0 - maximum: 3040.0  median: 774.0 minimum: 24.0\n",
      "Model 232 Saved\n",
      "Starting batch 39\n",
      "Generation 0 - maximum: 2988.0  median: 782.0 minimum: 24.0\n",
      "Model 233 Saved\n",
      "Starting batch 40\n",
      "Generation 0 - maximum: 2972.0  median: 778.0 minimum: 24.0\n",
      "Model 234 Saved\n",
      "Starting batch 41\n",
      "Generation 0 - maximum: 2916.0  median: 778.0 minimum: 24.0\n",
      "Model 235 Saved\n",
      "Starting batch 42\n",
      "Generation 0 - maximum: 2950.0  median: 788.0 minimum: 24.0\n",
      "Model 236 Saved\n",
      "Starting batch 43\n",
      "Generation 0 - maximum: 2970.0  median: 788.0 minimum: 24.0\n",
      "Model 237 Saved\n",
      "Starting batch 44\n",
      "Generation 0 - maximum: 2980.0  median: 784.0 minimum: 24.0\n",
      "Model 238 Saved\n",
      "Starting batch 45\n",
      "Generation 0 - maximum: 2934.0  median: 784.0 minimum: 24.0\n",
      "Model 239 Saved\n",
      "Starting batch 46\n",
      "Generation 0 - maximum: 2950.0  median: 788.0 minimum: 24.0\n",
      "Model 240 Saved\n",
      "Starting batch 47\n",
      "Generation 0 - maximum: 3062.0  median: 786.0 minimum: 24.0\n",
      "Model 241 Saved\n",
      "Starting batch 48\n",
      "Generation 0 - maximum: 3030.0  median: 784.0 minimum: 24.0\n",
      "Model 242 Saved\n",
      "Starting batch 49\n",
      "Generation 0 - maximum: 2958.0  median: 782.0 minimum: 24.0\n",
      "Model 243 Saved\n",
      "Starting batch 50\n",
      "Generation 0 - maximum: 3006.0  median: 786.0 minimum: 24.0\n",
      "Model 244 Saved\n",
      "Starting batch 51\n",
      "Generation 0 - maximum: 2974.0  median: 789.0 minimum: 24.0\n",
      "Model 245 Saved\n",
      "Starting batch 52\n",
      "Generation 0 - maximum: 2992.0  median: 790.0 minimum: 24.0\n",
      "Model 246 Saved\n",
      "Starting batch 53\n",
      "Generation 0 - maximum: 3042.0  median: 788.0 minimum: 24.0\n",
      "Model 247 Saved\n",
      "Starting batch 54\n",
      "Generation 0 - maximum: 2986.0  median: 789.0 minimum: 24.0\n",
      "Model 248 Saved\n",
      "Starting batch 55\n",
      "Generation 0 - maximum: 2956.0  median: 790.0 minimum: 24.0\n",
      "Model 249 Saved\n",
      "Starting batch 56\n",
      "Generation 0 - maximum: 2970.0  median: 792.0 minimum: 24.0\n",
      "Model 250 Saved\n",
      "Starting batch 57\n",
      "Generation 0 - maximum: 2970.0  median: 792.0 minimum: 24.0\n",
      "Model 251 Saved\n",
      "Starting batch 58\n",
      "Generation 0 - maximum: 2958.0  median: 796.0 minimum: 24.0\n",
      "Model 252 Saved\n",
      "Starting batch 59\n",
      "Generation 0 - maximum: 3024.0  median: 792.0 minimum: 24.0\n",
      "Model 253 Saved\n",
      "Starting batch 60\n",
      "Generation 0 - maximum: 2936.0  median: 791.0 minimum: 24.0\n",
      "Model 254 Saved\n",
      "Starting batch 61\n",
      "Generation 0 - maximum: 3034.0  median: 792.0 minimum: 24.0\n",
      "Model 255 Saved\n",
      "Starting batch 62\n",
      "Generation 0 - maximum: 2972.0  median: 793.0 minimum: 24.0\n",
      "Model 256 Saved\n",
      "Starting batch 63\n",
      "Generation 0 - maximum: 3012.0  median: 786.0 minimum: 24.0\n",
      "Model 257 Saved\n",
      "Starting batch 64\n",
      "Generation 0 - maximum: 2982.0  median: 792.0 minimum: 24.0\n",
      "Model 258 Saved\n",
      "Starting batch 65\n",
      "Generation 0 - maximum: 2988.0  median: 794.0 minimum: 24.0\n",
      "Model 259 Saved\n",
      "Starting batch 66\n",
      "Generation 0 - maximum: 3100.0  median: 794.0 minimum: 24.0\n",
      "Model 260 Saved\n",
      "Starting batch 67\n",
      "Generation 0 - maximum: 3010.0  median: 790.0 minimum: 24.0\n",
      "Model 261 Saved\n",
      "Starting batch 68\n",
      "Generation 0 - maximum: 3042.0  median: 794.0 minimum: 24.0\n",
      "Model 262 Saved\n",
      "Starting batch 69\n",
      "Generation 0 - maximum: 2974.0  median: 796.0 minimum: 24.0\n",
      "Model 263 Saved\n",
      "Starting batch 70\n",
      "Generation 0 - maximum: 3012.0  median: 794.0 minimum: 24.0\n",
      "Model 264 Saved\n",
      "Starting batch 71\n",
      "Generation 0 - maximum: 2954.0  median: 794.0 minimum: 24.0\n",
      "Model 265 Saved\n",
      "Starting batch 72\n",
      "Generation 0 - maximum: 2922.0  median: 788.0 minimum: 24.0\n",
      "Model 266 Saved\n",
      "Starting batch 73\n",
      "Generation 0 - maximum: 3028.0  median: 794.0 minimum: 24.0\n",
      "Model 267 Saved\n",
      "Starting batch 74\n",
      "Generation 0 - maximum: 2996.0  median: 796.0 minimum: 24.0\n",
      "Model 268 Saved\n",
      "Starting batch 75\n",
      "Generation 0 - maximum: 2954.0  median: 798.0 minimum: 24.0\n",
      "Model 269 Saved\n",
      "Starting batch 76\n",
      "Generation 0 - maximum: 2978.0  median: 800.0 minimum: 24.0\n",
      "Model 270 Saved\n",
      "Starting batch 77\n",
      "Generation 0 - maximum: 2974.0  median: 801.0 minimum: 24.0\n",
      "Model 271 Saved\n",
      "Starting batch 78\n",
      "Generation 0 - maximum: 2988.0  median: 798.0 minimum: 24.0\n",
      "Model 272 Saved\n",
      "Starting batch 79\n",
      "Generation 0 - maximum: 3042.0  median: 800.0 minimum: 24.0\n",
      "Model 273 Saved\n",
      "Starting batch 80\n",
      "Generation 0 - maximum: 3028.0  median: 800.0 minimum: 24.0\n",
      "Model 274 Saved\n",
      "Starting batch 81\n",
      "Generation 0 - maximum: 3114.0  median: 800.0 minimum: 24.0\n",
      "Model 275 Saved\n",
      "Starting batch 82\n",
      "Generation 0 - maximum: 2974.0  median: 800.0 minimum: 24.0\n",
      "Model 276 Saved\n",
      "Starting batch 83\n",
      "Generation 0 - maximum: 3076.0  median: 798.0 minimum: 24.0\n",
      "Model 277 Saved\n",
      "Starting batch 84\n",
      "Generation 0 - maximum: 3042.0  median: 802.0 minimum: 24.0\n",
      "Model 278 Saved\n",
      "Starting batch 85\n",
      "Generation 0 - maximum: 2952.0  median: 802.0 minimum: 24.0\n",
      "Model 279 Saved\n",
      "Starting batch 86\n",
      "Generation 0 - maximum: 3010.0  median: 806.0 minimum: 24.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 280 Saved\n",
      "Starting batch 87\n",
      "Generation 0 - maximum: 2992.0  median: 806.0 minimum: 24.0\n",
      "Model 281 Saved\n",
      "Starting batch 88\n",
      "Generation 0 - maximum: 3002.0  median: 798.0 minimum: 24.0\n",
      "Model 282 Saved\n",
      "Starting batch 89\n",
      "Generation 0 - maximum: 2984.0  median: 802.0 minimum: 24.0\n",
      "Model 283 Saved\n",
      "Starting batch 90\n",
      "Generation 0 - maximum: 2982.0  median: 802.0 minimum: 24.0\n",
      "Model 284 Saved\n",
      "Starting batch 91\n",
      "Generation 0 - maximum: 3044.0  median: 800.0 minimum: 24.0\n",
      "Model 285 Saved\n",
      "Starting batch 92\n",
      "Generation 0 - maximum: 3044.0  median: 802.0 minimum: 24.0\n",
      "Model 286 Saved\n",
      "Starting batch 93\n",
      "Generation 0 - maximum: 3030.0  median: 802.0 minimum: 24.0\n",
      "Model 287 Saved\n",
      "Starting batch 94\n",
      "Generation 0 - maximum: 2996.0  median: 800.0 minimum: 24.0\n",
      "Model 288 Saved\n",
      "Starting batch 95\n",
      "Generation 0 - maximum: 2980.0  median: 806.0 minimum: 24.0\n",
      "Model 289 Saved\n",
      "Starting batch 96\n",
      "Generation 0 - maximum: 3046.0  median: 800.0 minimum: 24.0\n",
      "Model 290 Saved\n",
      "Starting batch 97\n",
      "Generation 0 - maximum: 2994.0  median: 800.0 minimum: 24.0\n",
      "Model 291 Saved\n",
      "Starting batch 98\n",
      "Generation 0 - maximum: 3026.0  median: 804.0 minimum: 24.0\n",
      "Model 292 Saved\n",
      "Starting batch 99\n",
      "Generation 0 - maximum: 3004.0  median: 808.0 minimum: 24.0\n",
      "Model 293 Saved\n",
      "Starting batch 100\n",
      "Generation 0 - maximum: 3012.0  median: 802.0 minimum: 24.0\n",
      "Model 294 Saved\n",
      "Starting batch 101\n",
      "Generation 0 - maximum: 3046.0  median: 802.0 minimum: 24.0\n",
      "Model 295 Saved\n",
      "Starting batch 102\n",
      "Generation 0 - maximum: 3068.0  median: 806.0 minimum: 24.0\n",
      "Model 296 Saved\n",
      "Starting batch 103\n",
      "Generation 0 - maximum: 2976.0  median: 800.0 minimum: 24.0\n",
      "Model 297 Saved\n",
      "Starting batch 104\n"
     ]
    }
   ],
   "source": [
    "from classGeneticLearner import GeneticLearner\n",
    "fname = 'models/model_'\n",
    "gen_to_load = 193\n",
    "generations_per_batch = 1\n",
    "n_batches = 1000\n",
    "total_generations = generations_per_batch * n_batches\n",
    "full_filename = fname+str(gen_to_load)+'.p'\n",
    "print('Loading ' + full_filename + ' and running ' + str(total_generations) + ' more generations')\n",
    "try:\n",
    "    G = load_model_state(full_filename)\n",
    "except:\n",
    "    raise ValueError('File does not exist: ' + full_filename)\n",
    "for i in range(n_batches):\n",
    "    print(\"Starting batch \"+str(i))\n",
    "    G.run_n_generations(generations_per_batch)\n",
    "    gen_num = (1+i)*generations_per_batch + gen_to_load\n",
    "    save_model_state(G,fname + str(gen_num) + '.p')\n",
    "    print(\"Model \" + str(gen_num) + \" Saved\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = 'models/model_'\n",
    "n_new_games = 2\n",
    "G = load_model_state(fname + '.p')\n",
    "A = G.get_best_agent()\n",
    "root = tk.Tk()\n",
    "root.title(\"2048 Game\")\n",
    "score,win = A.replay_previous_game(root)\n",
    "print('Agent score: '+str(score)+' Win status: '+ str(win))\n",
    "time.sleep(0.5)\n",
    "for i in range(n_new_games):\n",
    "    score, win = A.play_game(root)\n",
    "    print('Agent score: ' + str(score) + ' Win status: ' + str(win))\n",
    "    time.sleep(0.5)\n",
    "\n",
    "input(\"Press Enter to end...\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
