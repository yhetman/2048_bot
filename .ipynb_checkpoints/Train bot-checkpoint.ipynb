{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math, copy\n",
    "import numpy as np\n",
    "\n",
    "from classNeuron import Neuron\n",
    "from classNetwork import Network\n",
    "import numpy as np\n",
    "from classGame2048 import Game2048\n",
    "import math\n",
    "# import classGame2048 as classGame2048\n",
    "import tkinter as tk\n",
    "import time\n",
    "import pickle\n",
    "import concurrent.futures\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0.]\n",
      " [4. 0. 4. 0.]\n",
      " [0. 0. 0. 2.]\n",
      " [0. 2. 0. 0.]]\n",
      "====================\n",
      "[[0. 0. 0. 0.]\n",
      " [0. 0. 0. 8.]\n",
      " [0. 0. 2. 2.]\n",
      " [0. 0. 0. 2.]]\n",
      "--------------------\n",
      "[0. 0. 0. 0. 0. 0. 0. 8. 0. 0. 2. 2. 0. 0. 0. 2.]\n",
      "--------------------\n",
      "94.0\n"
     ]
    }
   ],
   "source": [
    "mygame = Game2048(4)\n",
    "mygame.generate_tile()\n",
    "mygame.generate_tile()\n",
    "mygame.show_state()\n",
    "print('====================')\n",
    "mygame.swipe('right')\n",
    "mygame.show_state()\n",
    "print('--------------------')\n",
    "print(mygame.get_state(True))\n",
    "print('--------------------')\n",
    "print(mygame.get_score())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Neuron class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.0\n"
     ]
    }
   ],
   "source": [
    "n = Neuron(np.array([-100, -100]), -100000)\n",
    "print(n.forward(np.array([25600000, 25600000])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.99980999 -1.        ]\n"
     ]
    }
   ],
   "source": [
    "X1 = np.array([[1], [4], [2], [-4]])\n",
    "X2 = np.array([[1, 2, 3,-3], [5,-20,12,0.26]])\n",
    "b1 = np.array([1,1,1,1])\n",
    "b2 = np.array([1,1])\n",
    "N = Network([X1,X2],[b1,b2])\n",
    "I = np.array([1,0.3,-1,3])\n",
    "print(N.evaluate(I))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing to run 10 generations...\n",
      "Starting batch 0\n",
      "Generation 0 - maximum: 436.0  median: 96.0 minimum: 24.0\n",
      "Model 0 Saved\n",
      "Starting batch 1\n",
      "Generation 0 - maximum: 768.0  median: 92.0 minimum: 24.0\n",
      "Model 1 Saved\n",
      "Starting batch 2\n",
      "Generation 0 - maximum: 748.0  median: 96.0 minimum: 24.0\n",
      "Model 2 Saved\n",
      "Starting batch 3\n",
      "Generation 0 - maximum: 1618.0  median: 98.0 minimum: 24.0\n",
      "Model 3 Saved\n",
      "Starting batch 4\n",
      "Generation 0 - maximum: 448.0  median: 98.0 minimum: 24.0\n",
      "Model 4 Saved\n",
      "Starting batch 5\n",
      "Generation 0 - maximum: 458.0  median: 100.0 minimum: 24.0\n",
      "Model 5 Saved\n",
      "Starting batch 6\n",
      "Generation 0 - maximum: 826.0  median: 100.0 minimum: 24.0\n",
      "Model 6 Saved\n",
      "Starting batch 7\n",
      "Generation 0 - maximum: 824.0  median: 100.0 minimum: 24.0\n",
      "Model 7 Saved\n",
      "Starting batch 8\n",
      "Generation 0 - maximum: 804.0  median: 100.0 minimum: 24.0\n",
      "Model 8 Saved\n",
      "Starting batch 9\n",
      "Generation 0 - maximum: 862.0  median: 104.0 minimum: 24.0\n",
      "Model 9 Saved\n"
     ]
    }
   ],
   "source": [
    "from classGeneticLearner import GeneticLearner\n",
    "\n",
    "fname = './models/model_'\n",
    "n_agents = 1000\n",
    "generations_per_batch = 1\n",
    "n_batches = 10\n",
    "total_generations = generations_per_batch * n_batches\n",
    "print('Preparing to run ' + str(total_generations) +' generations...')\n",
    "\n",
    "G = GeneticLearner(n_agents,[16,8,4],seed = 4)\n",
    "for i in range(n_batches):\n",
    "    print(\"Starting batch \" + str(i))\n",
    "    G.run_n_generations(generations_per_batch)\n",
    "    gen_num = i * generations_per_batch\n",
    "    save_model_state(G, fname + str(gen_num) + '.p')\n",
    "    print(\"Model \" + str(gen_num) + \" Saved\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conitnue training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading models/model_193.p and running 1000 more generations\n",
      "Starting batch 0\n",
      "Generation 0 - maximum: 1606.0  median: 444.0 minimum: 24.0\n",
      "Model 194 Saved\n",
      "Starting batch 1\n",
      "Generation 0 - maximum: 1584.0  median: 452.0 minimum: 24.0\n",
      "Model 195 Saved\n",
      "Starting batch 2\n",
      "Generation 0 - maximum: 1594.0  median: 444.0 minimum: 24.0\n",
      "Model 196 Saved\n",
      "Starting batch 3\n",
      "Generation 0 - maximum: 1634.0  median: 444.0 minimum: 24.0\n",
      "Model 197 Saved\n",
      "Starting batch 4\n",
      "Generation 0 - maximum: 1586.0  median: 444.0 minimum: 24.0\n",
      "Model 198 Saved\n",
      "Starting batch 5\n",
      "Generation 0 - maximum: 2912.0  median: 450.0 minimum: 24.0\n",
      "Model 199 Saved\n",
      "Starting batch 6\n",
      "Generation 0 - maximum: 1612.0  median: 450.0 minimum: 24.0\n",
      "Model 200 Saved\n",
      "Starting batch 7\n",
      "Generation 0 - maximum: 1608.0  median: 450.0 minimum: 24.0\n",
      "Model 201 Saved\n",
      "Starting batch 8\n",
      "Generation 0 - maximum: 2950.0  median: 451.0 minimum: 24.0\n",
      "Model 202 Saved\n",
      "Starting batch 9\n",
      "Generation 0 - maximum: 2946.0  median: 455.0 minimum: 24.0\n",
      "Model 203 Saved\n",
      "Starting batch 10\n",
      "Generation 0 - maximum: 1604.0  median: 458.0 minimum: 24.0\n",
      "Model 204 Saved\n",
      "Starting batch 11\n",
      "Generation 0 - maximum: 2950.0  median: 456.0 minimum: 24.0\n",
      "Model 205 Saved\n",
      "Starting batch 12\n",
      "Generation 0 - maximum: 1632.0  median: 453.0 minimum: 24.0\n",
      "Model 206 Saved\n",
      "Starting batch 13\n",
      "Generation 0 - maximum: 1608.0  median: 448.0 minimum: 24.0\n",
      "Model 207 Saved\n",
      "Starting batch 14\n",
      "Generation 0 - maximum: 2954.0  median: 450.0 minimum: 24.0\n",
      "Model 208 Saved\n",
      "Starting batch 15\n",
      "Generation 0 - maximum: 1632.0  median: 479.0 minimum: 24.0\n",
      "Model 209 Saved\n",
      "Starting batch 16\n",
      "Generation 0 - maximum: 2916.0  median: 460.0 minimum: 24.0\n",
      "Model 210 Saved\n",
      "Starting batch 17\n",
      "Generation 0 - maximum: 1576.0  median: 754.0 minimum: 24.0\n",
      "Model 211 Saved\n",
      "Starting batch 18\n",
      "Generation 0 - maximum: 2958.0  median: 465.0 minimum: 24.0\n",
      "Model 212 Saved\n",
      "Starting batch 19\n",
      "Generation 0 - maximum: 2956.0  median: 745.0 minimum: 24.0\n",
      "Model 213 Saved\n",
      "Starting batch 20\n",
      "Generation 0 - maximum: 2932.0  median: 756.0 minimum: 24.0\n",
      "Model 214 Saved\n",
      "Starting batch 21\n",
      "Generation 0 - maximum: 1612.0  median: 464.0 minimum: 24.0\n",
      "Model 215 Saved\n",
      "Starting batch 22\n",
      "Generation 0 - maximum: 2940.0  median: 465.0 minimum: 24.0\n",
      "Model 216 Saved\n",
      "Starting batch 23\n",
      "Generation 0 - maximum: 1624.0  median: 480.0 minimum: 24.0\n",
      "Model 217 Saved\n",
      "Starting batch 24\n",
      "Generation 0 - maximum: 1630.0  median: 756.0 minimum: 24.0\n",
      "Model 218 Saved\n",
      "Starting batch 25\n",
      "Generation 0 - maximum: 1594.0  median: 761.0 minimum: 24.0\n",
      "Model 219 Saved\n",
      "Starting batch 26\n",
      "Generation 0 - maximum: 1614.0  median: 769.0 minimum: 24.0\n",
      "Model 220 Saved\n",
      "Starting batch 27\n",
      "Generation 0 - maximum: 3002.0  median: 774.0 minimum: 24.0\n",
      "Model 221 Saved\n",
      "Starting batch 28\n",
      "Generation 0 - maximum: 2940.0  median: 758.0 minimum: 24.0\n",
      "Model 222 Saved\n",
      "Starting batch 29\n",
      "Generation 0 - maximum: 1604.0  median: 768.0 minimum: 24.0\n",
      "Model 223 Saved\n",
      "Starting batch 30\n",
      "Generation 0 - maximum: 2920.0  median: 758.0 minimum: 24.0\n",
      "Model 224 Saved\n",
      "Starting batch 31\n",
      "Generation 0 - maximum: 1596.0  median: 768.0 minimum: 24.0\n",
      "Model 225 Saved\n",
      "Starting batch 32\n",
      "Generation 0 - maximum: 1604.0  median: 770.0 minimum: 24.0\n",
      "Model 226 Saved\n",
      "Starting batch 33\n",
      "Generation 0 - maximum: 2992.0  median: 770.0 minimum: 24.0\n",
      "Model 227 Saved\n",
      "Starting batch 34\n",
      "Generation 0 - maximum: 2962.0  median: 774.0 minimum: 24.0\n",
      "Model 228 Saved\n",
      "Starting batch 35\n",
      "Generation 0 - maximum: 2954.0  median: 766.0 minimum: 24.0\n",
      "Model 229 Saved\n",
      "Starting batch 36\n",
      "Generation 0 - maximum: 2914.0  median: 776.0 minimum: 24.0\n",
      "Model 230 Saved\n",
      "Starting batch 37\n",
      "Generation 0 - maximum: 2980.0  median: 780.0 minimum: 24.0\n",
      "Model 231 Saved\n",
      "Starting batch 38\n",
      "Generation 0 - maximum: 3040.0  median: 774.0 minimum: 24.0\n",
      "Model 232 Saved\n",
      "Starting batch 39\n",
      "Generation 0 - maximum: 2988.0  median: 782.0 minimum: 24.0\n",
      "Model 233 Saved\n",
      "Starting batch 40\n",
      "Generation 0 - maximum: 2972.0  median: 778.0 minimum: 24.0\n",
      "Model 234 Saved\n",
      "Starting batch 41\n",
      "Generation 0 - maximum: 2916.0  median: 778.0 minimum: 24.0\n",
      "Model 235 Saved\n",
      "Starting batch 42\n",
      "Generation 0 - maximum: 2950.0  median: 788.0 minimum: 24.0\n",
      "Model 236 Saved\n",
      "Starting batch 43\n",
      "Generation 0 - maximum: 2970.0  median: 788.0 minimum: 24.0\n",
      "Model 237 Saved\n",
      "Starting batch 44\n",
      "Generation 0 - maximum: 2980.0  median: 784.0 minimum: 24.0\n",
      "Model 238 Saved\n",
      "Starting batch 45\n",
      "Generation 0 - maximum: 2934.0  median: 784.0 minimum: 24.0\n",
      "Model 239 Saved\n",
      "Starting batch 46\n",
      "Generation 0 - maximum: 2950.0  median: 788.0 minimum: 24.0\n",
      "Model 240 Saved\n",
      "Starting batch 47\n",
      "Generation 0 - maximum: 3062.0  median: 786.0 minimum: 24.0\n",
      "Model 241 Saved\n",
      "Starting batch 48\n",
      "Generation 0 - maximum: 3030.0  median: 784.0 minimum: 24.0\n",
      "Model 242 Saved\n",
      "Starting batch 49\n",
      "Generation 0 - maximum: 2958.0  median: 782.0 minimum: 24.0\n",
      "Model 243 Saved\n",
      "Starting batch 50\n",
      "Generation 0 - maximum: 3006.0  median: 786.0 minimum: 24.0\n",
      "Model 244 Saved\n",
      "Starting batch 51\n",
      "Generation 0 - maximum: 2974.0  median: 789.0 minimum: 24.0\n",
      "Model 245 Saved\n",
      "Starting batch 52\n",
      "Generation 0 - maximum: 2992.0  median: 790.0 minimum: 24.0\n",
      "Model 246 Saved\n",
      "Starting batch 53\n",
      "Generation 0 - maximum: 3042.0  median: 788.0 minimum: 24.0\n",
      "Model 247 Saved\n",
      "Starting batch 54\n",
      "Generation 0 - maximum: 2986.0  median: 789.0 minimum: 24.0\n",
      "Model 248 Saved\n",
      "Starting batch 55\n",
      "Generation 0 - maximum: 2956.0  median: 790.0 minimum: 24.0\n",
      "Model 249 Saved\n",
      "Starting batch 56\n",
      "Generation 0 - maximum: 2970.0  median: 792.0 minimum: 24.0\n",
      "Model 250 Saved\n",
      "Starting batch 57\n",
      "Generation 0 - maximum: 2970.0  median: 792.0 minimum: 24.0\n",
      "Model 251 Saved\n",
      "Starting batch 58\n",
      "Generation 0 - maximum: 2958.0  median: 796.0 minimum: 24.0\n",
      "Model 252 Saved\n",
      "Starting batch 59\n",
      "Generation 0 - maximum: 3024.0  median: 792.0 minimum: 24.0\n",
      "Model 253 Saved\n",
      "Starting batch 60\n",
      "Generation 0 - maximum: 2936.0  median: 791.0 minimum: 24.0\n",
      "Model 254 Saved\n",
      "Starting batch 61\n",
      "Generation 0 - maximum: 3034.0  median: 792.0 minimum: 24.0\n",
      "Model 255 Saved\n",
      "Starting batch 62\n",
      "Generation 0 - maximum: 2972.0  median: 793.0 minimum: 24.0\n",
      "Model 256 Saved\n",
      "Starting batch 63\n",
      "Generation 0 - maximum: 3012.0  median: 786.0 minimum: 24.0\n",
      "Model 257 Saved\n",
      "Starting batch 64\n",
      "Generation 0 - maximum: 2982.0  median: 792.0 minimum: 24.0\n",
      "Model 258 Saved\n",
      "Starting batch 65\n",
      "Generation 0 - maximum: 2988.0  median: 794.0 minimum: 24.0\n",
      "Model 259 Saved\n",
      "Starting batch 66\n",
      "Generation 0 - maximum: 3100.0  median: 794.0 minimum: 24.0\n",
      "Model 260 Saved\n",
      "Starting batch 67\n",
      "Generation 0 - maximum: 3010.0  median: 790.0 minimum: 24.0\n",
      "Model 261 Saved\n",
      "Starting batch 68\n",
      "Generation 0 - maximum: 3042.0  median: 794.0 minimum: 24.0\n",
      "Model 262 Saved\n",
      "Starting batch 69\n"
     ]
    }
   ],
   "source": [
    "from classGeneticLearner import GeneticLearner\n",
    "fname = 'models/model_'\n",
    "gen_to_load = 193\n",
    "generations_per_batch = 1\n",
    "n_batches = 1000\n",
    "total_generations = generations_per_batch * n_batches\n",
    "full_filename = fname+str(gen_to_load)+'.p'\n",
    "print('Loading ' + full_filename + ' and running ' + str(total_generations) + ' more generations')\n",
    "try:\n",
    "    G = load_model_state(full_filename)\n",
    "except:\n",
    "    raise ValueError('File does not exist: ' + full_filename)\n",
    "for i in range(n_batches):\n",
    "    print(\"Starting batch \"+str(i))\n",
    "    G.run_n_generations(generations_per_batch)\n",
    "    gen_num = (1+i)*generations_per_batch + gen_to_load\n",
    "    save_model_state(G,fname + str(gen_num) + '.p')\n",
    "    print(\"Model \" + str(gen_num) + \" Saved\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = 'models/model_'\n",
    "n_new_games = 2\n",
    "G = load_model_state(fname + '.p')\n",
    "A = G.get_best_agent()\n",
    "root = tk.Tk()\n",
    "root.title(\"2048 Game\")\n",
    "score,win = A.replay_previous_game(root)\n",
    "print('Agent score: '+str(score)+' Win status: '+ str(win))\n",
    "time.sleep(0.5)\n",
    "for i in range(n_new_games):\n",
    "    score, win = A.play_game(root)\n",
    "    print('Agent score: ' + str(score) + ' Win status: ' + str(win))\n",
    "    time.sleep(0.5)\n",
    "\n",
    "input(\"Press Enter to end...\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
